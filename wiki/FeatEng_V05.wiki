#summary Feature Engineering v0.5

= Introduction =
For a high-level overview of the feature engineering methods we've developed, refer to our paper: Garla, V and Brandt, C. Ontology-Guided Feature Engineering for Clinical Text Classification (submitted).

We developed a feature ranking method that utilizes the taxonomical structure of the UMLS to improve feature ranking; a context-dependent semantic similarity measure; and implemented a semantic kernel.  We improved the performance of the top-ranked machine learning-based system from the [https://www.i2b2.org/NLP/Obesity/ I2B2 2008 challenge] with these methods.  

These feature engineering tools are included in YTEX, but do not depend on the YTEX NLP Pipeline: they can be used in conjunction with any text mining or NLP system.

The main tools are:
  * ConceptDaoImpl: This tool generates a concept graph from the UMLS.  You can declaratively define which UMLS source vocabularies and relationships to use to define this concept graph.  
  * ImputedFeatureEvaluator: This computes the propagated and imputed information gain of all concepts in a corpus.
  * SemanticSimilarityService: This computes the semantic similarity of a pair of concepts.  We currently implement the Leacock-Chodorow, Lin, and Supervised Lin measures.
  * CorpusKernelEvaluator: Evaluate a user-defined kernel on all pairs of documents in a corpus.  The kernel matrices can be exported to data mining tools such as Matlab, R, or Libsvm for machine learning.  We have implemented a semantic kernel that uses the SemanticSimilarityService.


In our discussion, we refer to the I2B2 2008 challenge dataset; you may want to reproduce our results on this dataset before getting into details.  Reproducing our results requires a little bit of setup, and will just run overnight.  We are currently developing tools to simplify the application of these methods to user-defined corpora.

= I2B2 2008 =
This section describes how to reproduce our results on the I2B2 2008 challenge dataset.

== Prerequisites ==
  * Quad Core workstation at the minimum; 8 cores would be better
  * [http://code.google.com/p/ytex/wiki/InstallationV05 Install umls 2010AB] or higher in your MySQL
  * [http://code.google.com/p/ytex/wiki/InstallationV05 Install YTEX v0.5] with MySQL (configured to use the UMLS)
  * [http://www.csie.ntu.edu.tw/~cjlin/libsvm/ Install libsvm 3.1] or higher
  * Download [https://www.i2b2.org/NLP/Obesity/ I2B2 2008 Challenge] data and extract all I2B2 2008 data files to some directory, referred to as `i2b2.dir`.  The following files are required:
     * obesity_patient_records_training2.xml
     * obesity_patient_records_test.xml
     * obesity_standoff_annotations_training.xml
     * obesity_standoff_annotations_test.xml
     * obesity_standoff_annotations_training_addendum.xml
     * obesity_standoff_annotations_training_addendum2.xml
     * obesity_standoff_annotations_training_addendum3.xml
  * Download i2b2-2008-v05.zip from this site, extract to your ytex home directory: you should have a folder `YTEX_HOME/i2b2.2008` when you are finished.
  * Install ytex data mining tables: open a command prompt and run the following commands:
{{{
cd YTEX_HOME
setenv.cmd
cd data
ant -Dytex.home=%YTEX_HOME kernel.create
}}}
  
== Configure ytex.properties ==
Add the following to your `ytex.properties` file:
{{{
# where challenge data was extracted
i2b2.dir=C:/downloads/text mining/i2b2 2008 challenge
# where libsvm binaries are located
libsvm.bin=C:/java/libsvm-3.1/windows
# where ytex is installed  
ytex.home=C:/clinicalnlp/ytex
# we generate a file that contains the umls concept graph 
# this is where we store it, adjust to match your environment
ytex.conceptGraphDir=C:/clinicalnlp/ytex/conceptGraph
# how many cores does your system have? 
# should have atleast 4, or this will take more than a weekend
kernel.threads=4
# the slices should go from 1 ... kernel.threads
kernel.slices=1,2,3,4
# where to place temporary files
kernel.eval.tmpdir=C:/temp
# copy the rest as is
parallel.folds=yes
kernel.name=i2b2.2008
ytex.conceptGraphName=rbpar
ytex.corpusName=i2b2.2008
ytex.conceptSetName=ctakes
}}}

== Reproduce results ==
This is completely automated by an ant build script.  We have split this up unto several high-level steps:
  * Setup: load and annotate the corpus, compute information-theoretic measures for all features (words, concepts) in the corpus.
  * Cross-Validation: perform cross-validation on the i2b2 training set to find the optimal parameters.  We have obviously already done this, so you can skip this step if you prefer.
  * Test: train models on the training set using optimal parameters, apply to test set.

=== Setup ===
To load and annotate the corpus, compute hotspots, open a command prompt, cd to the `YTEX_HOME/i2b2.2008` directory, and run the following from the commands (this will take ~4 hours w/ 4 cores):
{{{
ant -Dytex.home=%YTEX_HOME% setup.all 
}}} 

=== Cross-Validation and Test ===
To run the cross validation and test, run the following (will take ~12 hours w/ 4 cores):
{{{
ant -Dytex.home=%YTEX_HOME% cv.all test.all
}}}

=== Test Only ===
To run just the test using the optimal parameters we found (will take ~4 hours w/ 4 cores):
{{{
ant -Dytex.home=%YTEX_HOME% test.skip.cv test.all
}}}

== Setup ==
We did the following in the setup:
  * load i2b2: Load i2b2 data - the notes and class labels - into the database
  * setup v_i2b2_fword_lookup:  Created a dictionary lookup table from the umls 
  * run cpe: annotated i2b2.2008 corpus with the YTEX Pipeline
  * setup tfidf: compute tf-idf statistics on corpus
  * evaluate infogain: compute infogain of each word for each label (disease) in the i2b2 corpus
  * Generate Concept Graph: generate an acyclic directed graph representing the taxonomical relationships from the UMLS
  * evaluate infocontent: compute information content of each concept in the i2b2 corpus
  * evaluate imputed infogain: compute imputed infogain of each concept for each label in the i2b2 corpus
  * generate folds: generate stratified cross-validation folds

=== Load I2B2 Data ===
We load the i2b2 data into the `corpus_doc` and `corpus_label` tables, which hold the documents and their labels respectively.

=== Setup v_i2b2_fword_lookup ===
We create a dictionary lookup table that uses the following UMLS Source Vocabularies:
  * SRC
  * MTH
  * RXNORM
  * SNOMEDCT
  * MSH
  * CSP
  * MEDLINEPLUS
  * MEDCIN
Refer to `YTEX_HOME\i2b2.2008\data\v_i2b2_fword_lookup.sql`

=== Run CPE ===
We annotate the corpus with the YTEX pipeline.  We launch several CPE processes (as many cores as you have) in parallel to speed up processing.  We also only store the sentence, word, number, and named entity annotations to speed up processing.  Refer to `YTEX_HOME\i2b2.2008\desc\cpe.template.xml`.

=== Setup tfidf ===
We compute tf-idf statistics on CUIs and store them in the `feature_eval` and `feature_rank` tables; refer to `YTEX_HOME\i2b2.2008\data\tfidf-cui.sql`.  Later during classification, we perform frequency thresholding on CUIs.

=== Evaluate infogain ===
We evaluate the infogain of all words wrt all i2b2 labels, using only the i2b2 training data.  This is done by the `WekaAttributeEvaluatorImpl` which calls the WEKA [http://weka.sourceforge.net/doc.dev/weka/attributeSelection/InfoGainAttributeEval.html `InfoGainAttributeEval`].  We store the evaluations in the `feature_eval` and `feature_rank` tables.  To view e.g. the top ranked words for hypertension, run the following query:
{{{
select r.feature_name, r.evaluation, r.rank
from feature_eval fe 
inner join feature_rank r 
    on r.feature_eval_id = fe.feature_eval_id
where fe.type = 'InfoGainAttributeEval' 
    and fe.label = 'Hypertension'
    and fe.featureset_name = 'usword'
    and r.rank < 11
order by rank;
}}}

=== Generate Concept Graph ===
We generate a graph that represents the umls taxonomy, and store this concept graph for subsequent use.  The YTEX `ConceptDaoImpl` takes as input a properties file that specifies a query that retrieves all edges that will be used in the taxonomy, generates a graph, and removes cycles.  For the i2b2 corpus, we select edges using the following query: 
{{{
	select cui1, cui2 
	from umls.MRREL 
	where sab in ('RXNORM', 'SNOMEDCT', 'SRC')
	and rel in ('PAR', 'RB')
}}}
As you can see, you have a large degree of flexibility in choosing which concepts and edges to use in your concept graph - you can filter by source vocabulary (sab), relation type (rel), relation attribute (rela) and more.


=== Evaluate infocontent ===
We use infocontent to compute semantic similarity via the lin measure.  We evaluate the information content of each concept in the i2b2 corpus using the `InfoContentEvaluatorImpl` and store this in the `feature_rank` and `feature_eval` tables.  The `InfoContentEvaluatorImpl` is parameterized by a query that retrieves the raw frequency of each concept in the corpus:
{{{
select code, count(*)
from anno_ontology_concept o
inner join anno_base b on b.anno_base_id = o.anno_base_id
inner join document d on d.document_id = b.document_id
where d.analysis_batch in ('i2b2.2008')
group by code
}}}

=== Evaluate imputed infogain ===
The `ImputedFeatureEvaluator` computes the propagated and imputed information gain of every concept in the i2b2 corpus.  This is parameterized by queries that retrieve the document - class and document - concept relationships.
  * Document - Class - Label:
{{{
select d.instance_id, a.class, 1, a.label
from corpus_doc d
inner join corpus_label a 
on a.instance_id = d.instance_id 
and a.corpus_name = d.corpus_name
where d.doc_group = 'train'
and d.corpus_name = 'i2b2.2008'
}}}
  * Document - Concept:
{{{
select *, 1
from
(
    select distinct c.code, d.instance_id
    from corpus_doc d
    inner join corpus_label a 
        on a.instance_id = d.instance_id 
        and a.corpus_name = d.corpus_name    
    inner join ytex.document yd 
        on yd.uid = d.instance_id 
        and yd.analysis_batch = d.corpus_name
    inner join ytex.anno_base ac 
        on ac.document_id = yd.document_id
    inner join ytex.anno_ontology_concept c 
        on ac.anno_base_id = c.anno_base_id
    where d.doc_group = 'train'
    and d.corpus_name = 'i2b2.2008'
    and a.label = :label
) s
}}}
As you can see, you have a wide degree of flexibility in defining the document-concept relationship and document-class relationship.

The propagated and imputed infogain are stored in the `feature_rank` and `feature_eval` tables.  To view the propagated infogain for the hypertension label:
{{{
select r.feature_name, min(str), truncate(r.evaluation, 3), r.rank
from feature_eval fe 
inner join feature_rank r 
    on r.feature_eval_id = fe.feature_eval_id
left join umls.MRCONSO c 
    on c.cui = r.feature_name 
    and c.tty in ('PT', 'PN', 'BN', 'OCD') and lat = 'ENG'
where fe.type = 'infogain-propagated' 
    and fe.label = 'Hypertension'
    and r.rank < 50
group by r.feature_name, r.evaluation, r.rank
order by r.rank ;
}}}

And to view the imputed infogain:
{{{
select r.feature_name, min(str), truncate(r.evaluation, 3), r.rank
from feature_eval fe 
inner join feature_rank r 
    on r.feature_eval_id = fe.feature_eval_id
left join umls.MRCONSO c 
    on c.cui = r.feature_name 
    and c.tty in ('PT', 'PN', 'BN', 'OCD') and lat = 'ENG'
where fe.type = 'infogain-imputed' 
    and fe.label = 'Hypertension'
    and r.rank < 100
group by r.feature_name, r.evaluation, r.rank
order by r.rank ;
}}}

=== Generate Folds ===
We generate stratified cross-validation folds and store them in the `cv_fold` and `cv_fold_instance` tables using the `FoldGeneratorImpl`.  There is only one document in the training set for some label/class combinations; such documents are duplicated in the cv train/test sets.

== I2B2 Cross-Validation ==

== I2B2 Test ==