#summary Feature Engineering v0.5

= Introduction =
For a high-level overview of the feature engineering methods we've developed, refer to our paper: Garla, V and Brandt, C. Ontology-Guided Feature Engineering for Clinical Text Classification (submitted).

We developed a feature ranking method that utilizes the taxonomical structure of the UMLS to improve feature ranking; a context-dependent semantic similarity measure; and implemented a semantic kernel.  We improved the performance of the top-ranked machine learning-based system from the [https://www.i2b2.org/NLP/Obesity/ I2B2 2008 challenge] with these methods.  These feature engineering tools are included in YTEX.

In our discussion, we refer to the I2B2 2008 challenge dataset, so please reproduce our results on this dataset before we get into details.  This requires little manual intervention, and will just run overnight.  

We are currently developing tools to simplify the application of these methods to user-defined corpora.

= I2B2 2008 =
This section describes how to reproduce our results on the I2B2 2008 challenge dataset.

== Prerequisites ==
  * Quad Core workstation at the minimum; 8 cores would be better
  * [http://code.google.com/p/ytex/wiki/InstallationV05 Install umls 2010AB] or higher in your MySQL
  * [http://code.google.com/p/ytex/wiki/InstallationV05 Install YTEX v0.5] with MySQL (configured to use the UMLS)
  * [http://www.csie.ntu.edu.tw/~cjlin/libsvm/ Install libsvm 3.1] or higher
  * Download [https://www.i2b2.org/NLP/Obesity/ I2B2 2008 Challenge] data and extract all I2B2 2008 data files to some directory, referred to as `i2b2.dir`.  The following files are required:
     * obesity_patient_records_training2.xml
     * obesity_patient_records_test.xml
     * obesity_standoff_annotations_training.xml
     * obesity_standoff_annotations_test.xml
     * obesity_standoff_annotations_training_addendum.xml
     * obesity_standoff_annotations_training_addendum2.xml
     * obesity_standoff_annotations_training_addendum3.xml
  * Download i2b2-2008-v05.zip from this site, extract to your ytex home directory: you should have a folder `YTEX_HOME/i2b2.2008` when you are finished.
  * Install ytex data mining tables: open a command prompt and run the following commands:
{{{
cd YTEX_HOME
setenv.cmd
cd data
ant -Dytex.home=%YTEX_HOME kernel.create
}}}
  
== Configure ytex.properties ==
Add the following to your `ytex.properties` file:
{{{
# where challenge data was extracted
i2b2.dir=C:/downloads/text mining/i2b2 2008 challenge
# where libsvm binaries are located
libsvm.bin=C:/java/libsvm-3.1/windows
# where ytex is installed  
ytex.home=C:/clinicalnlp/ytex
# we generate a file that contains the umls concept graph 
# this is where we store it, adjust to match your environment
ytex.conceptGraphDir=C:/clinicalnlp/ytex/conceptGraph
# how many cores does your system have? 
# should have atleast 4, or this will take more than a weekend
kernel.threads=4
# the slices should go from 1 ... kernel.threads
kernel.slices=1,2,3,4
# where to place temporary files
kernel.eval.tmpdir=C:/temp
# copy the rest as is
parallel.folds=yes
kernel.name=i2b2.2008
ytex.conceptGraphName=rbpar
ytex.corpusName=i2b2.2008
ytex.conceptSetName=ctakes
}}}

== Reproducing results ==
To load and annotate the corpus, compute hotspots, open a command prompt, cd `ytex.home/i2b2.2008` directory, and run the following from the commands (this will take ~5 hours w/ 4 cores):
{{{
ant -Dytex.home=%YTEX_HOME% setup.all 
}}} 

To run the cross validation and test, run the following (will run an entire weekend):
{{{
ant -Dytex.home=%YTEX_HOME% cv.all test.all
}}}

To run just the test using the optimal parameters we found (will take ~6 hours w/ 4 cores):
{{{
ant -Dytex.home=%YTEX_HOME% test.skip.cv test.all
}}}

= Feature Engineering =

== Setup ==
We did the following in the setup:
  * load i2b2: Load i2b2 data - the notes and class labels - into the database
  * setup v_i2b2_fword_lookup:  Created a dictionary lookup table from the umls 
  * run cpe: annotated i2b2.2008 corpus with the YTEX Pipeline
  * setup tfidf: compute tf-idf statistics on corpus
  * evaluate infogain: compute infogain of each word for each label (disease) in the i2b2 corpus
  * Generate Concept Graph: generate an acyclic directed graph representing the taxonomical relationships from the UMLS
  * evaluate infocontent: compute information content of each concept in the i2b2 corpus
  * evaluate imputed infogain: compute imputed infogain of each concept for each label in the i2b2 corpus
  * generate folds: generate stratified cross-validation folds

=== Load I2B2 Data ===
We load the i2b2 data into the `corpus_doc` and `corpus_label` tables, which hold the documents and their labels respectively.

=== Setup v_i2b2_fword_lookup ===
We create a dictionary lookup table that uses the following UMLS Source Vocabularies:
  * SRC
  * MTH
  * RXNORM
  * SNOMEDCT
  * MSH
  * CSP
  * MEDLINEPLUS
  * MEDCIN
Refer to `YTEX_HOME\i2b2.2008\data\v_i2b2_fword_lookup.sql`

=== Run CPE ===
We annotate the corpus with the YTEX pipeline.  We launch several CPE processes (as many cores as you have) in parallel to speed up processing.  We also only store the sentence, word, number, and named entity annotations to speed up processing.  Refer to `YTEX_HOME\i2b2.2008\desc\cpe.template.xml`.

=== Setup tfidf ===
We compute tf-idf statistics on CUIs and store them in the `feature_eval` and `feature_rank` tables; refer to `YTEX_HOME\i2b2.2008\data\tfidf-cui.sql`.  Later during classification, we perform frequency thresholding on CUIs.

=== Evaluate infogain ===
We evaluate the infogain of all words wrt all i2b2 labels, using only the i2b2 training data.  This is done by the `WekaAttributeEvaluatorImpl` which calls the WEKA [http://weka.sourceforge.net/doc.dev/weka/attributeSelection/InfoGainAttributeEval.html `InfoGainAttributeEval`].  We store the evaluations in the `feature_eval` and `feature_rank` tables.  To view e.g. the top ranked words for hypertension, run the following query:
{{{
select r.feature_name, r.evaluation, r.rank
from feature_eval fe 
inner join feature_rank r 
    on r.feature_eval_id = fe.feature_eval_id
where fe.type = 'InfoGainAttributeEval' 
    and fe.label = 'Hypertension'
    and fe.featureset_name = 'usword'
    and r.rank < 11
order by rank;
}}}

=== Generate Concept Graph ===
We generate a graph that represents the umls taxonomy, and store this concept graph for subsequent use.  The YTEX `ConceptDaoImpl` takes as input a properties file that specifies a query that retrieves all edges that will be used in the taxonomy, generates a graph, and removes cycles.  For the i2b2 corpus, we select edges using the following query: 
{{{
	select cui1, cui2 
	from umls.MRREL 
	where sab in ('RXNORM', 'SNOMEDCT', 'SRC')
	and rel in ('PAR', 'RB')
}}}
As you can see, you have a large degree of flexibility in choosing which concepts and edges to use in your concept graph - you can filter by source vocabulary (sab), relation type (rel), relation attribute (rela) and more.


=== Evaluate infocontent ===
We use infocontent to compute semantic similarity via the lin measure.  We evaluate the information content of each concept in the i2b2 corpus using the `InfoContentEvaluatorImpl` and store this in the `feature_rank` and `feature_eval` tables.  The `InfoContentEvaluatorImpl` is parameterized by a query that retrieves the raw frequency of each concept in the corpus:
{{{
select code, count(*)
from anno_ontology_concept o
inner join anno_base b on b.anno_base_id = o.anno_base_id
inner join document d on d.document_id = b.document_id
where d.analysis_batch in ('i2b2.2008')
group by code
}}}

=== Evaluate imputed infogain ===
The `ImputedFeatureEvaluator` computes the propagated and imputed information gain of every concept in the i2b2 corpus.  This is parameterized by queries that retrieve the document - class and document - concept relationships.
  * Document - Class - Label:
{{{
select d.instance_id, a.class, 1, a.label
from corpus_doc d
inner join corpus_label a 
on a.instance_id = d.instance_id 
and a.corpus_name = d.corpus_name
where d.doc_group = 'train'
and d.corpus_name = 'i2b2.2008'
}}}
  * Document - Concept:
{{{
select *, 1
from
(
    select distinct c.code, d.instance_id
    from corpus_doc d
    inner join corpus_label a 
        on a.instance_id = d.instance_id 
        and a.corpus_name = d.corpus_name    
    inner join ytex.document yd 
        on yd.uid = d.instance_id 
        and yd.analysis_batch = d.corpus_name
    inner join ytex.anno_base ac 
        on ac.document_id = yd.document_id
    inner join ytex.anno_ontology_concept c 
        on ac.anno_base_id = c.anno_base_id
    where d.doc_group = 'train'
    and d.corpus_name = 'i2b2.2008'
    and a.label = :label
) s
}}}
As you can see, you have a wide degree of flexibility in defining the document-concept relationship and document-class relationship.

The propagated and imputed infogain are stored in the `feature_rank` and `feature_eval` tables.  To view the propagated infogain for the hypertension label:
{{{
select r.feature_name, min(str), truncate(r.evaluation, 3), r.rank
from feature_eval fe 
inner join feature_rank r 
    on r.feature_eval_id = fe.feature_eval_id
left join umls.MRCONSO c 
    on c.cui = r.feature_name 
    and c.tty in ('PT', 'PN', 'BN', 'OCD') and lat = 'ENG'
where fe.type = 'infogain-propagated' 
    and fe.label = 'Hypertension'
    and r.rank < 50
group by r.feature_name, r.evaluation, r.rank
order by r.rank ;
}}}

And to view the imputed infogain:
{{{
select r.feature_name, min(str), truncate(r.evaluation, 3), r.rank
from feature_eval fe 
inner join feature_rank r 
    on r.feature_eval_id = fe.feature_eval_id
left join umls.MRCONSO c 
    on c.cui = r.feature_name 
    and c.tty in ('PT', 'PN', 'BN', 'OCD') and lat = 'ENG'
where fe.type = 'infogain-imputed' 
    and fe.label = 'Hypertension'
    and r.rank < 100
group by r.feature_name, r.evaluation, r.rank
order by r.rank ;
}}}

=== Generate Folds ===
We generate stratified cross-validation folds and store them in the `cv_fold` and `cv_fold_instance` tables using the `FoldGeneratorImpl`.  There is only one document in the training set for some label/class combinations; such documents are duplicated in the cv train/test sets.

